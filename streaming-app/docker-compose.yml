version: '3.8'
networks:
  kafka-logstash-spark-collector:
    external: true

services:
  spark:
    image: docker.io/bitnami/spark:latest
    container_name: spark_master
    restart: unless-stopped
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    networks:
      - kafka-logstash-spark-collector
    ports:
      - '38080:8080'
      - '37077:7077'
    volumes:
      - ./app:/app
      - ./spark-conf/spark-defaults.conf:/bitnami/spark/conf/spark-defaults.conf

  spark-worker0:
    image: docker.io/bitnami/spark:latest
    container_name: spark_worker0
    depends_on: 
      - spark
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=4
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    networks:
      - kafka-logstash-spark-collector
    ports:
      - '38081:8081'
    volumes:
      - ./app:/app

  spark-app:
    image: docker.io/bitnami/spark:latest
    container_name: exec-spark-streaming-app
    depends_on: 
      - spark
      - spark-worker0
    volumes:
      - ./app:/app
    command: ./bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 /app/kafka-flight-topic-consumer.py
    user: root
    networks:
      - kafka-logstash-spark-collector
    environment:
      PYTHONPATH: /opt/bitnami/spark/python:/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip 
